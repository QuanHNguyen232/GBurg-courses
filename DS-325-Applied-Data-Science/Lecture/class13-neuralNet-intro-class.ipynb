{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "plt.rcParams[\"figure.figsize\"] = [9.708,6]\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#this is our new one\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the tensorflow version.  Should be >2.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(tf.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "The MNIST dataset is a dataset of 60,000 training and 10,000 test examples of handwritten digits, originally constructed by Yann Lecun, Corinna Cortes, and Christopher J.C. Burges. It is very widely used to check simple methods. There are 10 classes in total (\"0\" to \"9\"). This dataset has been extensively studied, and there is a history of methods and feature construc- tions at [https://en.wikipedia.org/wiki/MNIST_database](https://en.wikipedia.org/wiki/MNIST_database) and at the original site, [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/). You should notice that the best methods perform extremely well.\n",
    "\n",
    "You will be implementing a simple neutral network and should, with appropriate hyperparameter settings, get a test\n",
    "error of approximately 5% or better. Specifically, you will implement a neural network with a total of three\n",
    "layers: an input layer, a hidden layer, and an output layer. Please pay careful attention to the following\n",
    "implementation details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_classes= 10    # 10 digits \n",
    "batch_size = 128   # during training to find the gradient\n",
    "epochs     = 10    # how long to train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "input_shape= (X_train.shape[1],X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare the data\n",
    "Flatten the images, convert the class labels, and scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.unique(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each label will have to be transformed to a one-hot-encoding representation, i.e., a vector of length 10\n",
    "that has a single 1 in the position of the true class and 0 everywhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "Y_test  = tf.keras.utils.to_categorical(y_test,  num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data between 0-1\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32')   / 255\n",
    "#Reshape To Match The Keras's Expectations\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, input_shape[0], input_shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1,    input_shape[0], input_shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=y_train)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the data\n",
    "The MNIST dataset contains hand-written digits that are 28x28 pixels large. Here is one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj  = 325 #lets look at image 325\n",
    "# preview the images first\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "imgi = X_train[jj].reshape((input_shape[0],input_shape[1]))\n",
    "plt.imshow(imgi,interpolation='nearest',cmap=plt.cm.gray)\n",
    "plt.axis('off')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few examples of each of the digits (0-9) in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preview the images first\n",
    "fig=plt.figure()\n",
    "ncols,nrows = len(class_names), 4\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols,figsize=(12,5))\n",
    "print(axs.shape)\n",
    "for i in range(ncols):\n",
    "    inn = y_train==i      #mask to select only that class\n",
    "    Xi  = X_train[inn]    #select only X_train belonging to that class\n",
    "    for j in range(nrows):        \n",
    "        imgi = Xi[j].reshape((input_shape[0],input_shape[1]))\n",
    "        axs[j,i].imshow(imgi,interpolation='nearest',cmap=plt.cm.gray)\n",
    "        axs[j,i].axis('off')\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(hspace=.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Recognition\n",
    "\n",
    "Here is an example of using the network to classify whether the last image contains a small digit. Again, since we haven't trained the network yet, the predicted probability of the image containing a small digit is close to half. The \"network\" is unsure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple network\n",
    "Build and compile a basic model.\n",
    "\n",
    "Layers for our Network.\n",
    "\n",
    "* **Input layer** - size 784 \n",
    "    * flatten the input image (28x28).\n",
    "* **Hidden layer** - size 100\n",
    "    * Dense (fully connected) network from input layer to these 128 neuron hidden layer.\n",
    "* **Output layer** - size 10\n",
    "    * Dense layer (fully connected back to the 128 neuron hidden layer). The 10 is the number of classes.  Given an input image, our network should **light** up the corresponding neuron of our target.\n",
    "* **Softmax activation** - convert our output into a probability for each class.\n",
    "\n",
    "By default, TensorFlow initializes the weights with random (small) values. This allows us to break symmetry\n",
    "that occurs when all weights are initialized to 0.    (we explore that last today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([              # model type\n",
    "  tf.keras.layers.Flatten(input_shape=X_train[1].shape),  # input layer\n",
    "  tf.keras.layers.Dense(100, activation='relu'),  # hidden layer\n",
    "  tf.keras.layers.Dense(10),                      # output to each class, could just stop here\n",
    "  tf.keras.layers.Softmax()                       # convert to probability\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our network to make a prediction.  Since our model is untrained, our network predicts this sample as ~10% to each class. Our network is randomly guessing at the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#our output is the probability to each class\n",
    "predictions = model(X_train[:1]).numpy()\n",
    "print(predictions) ###each should be about 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our loss function\n",
    "\n",
    "The **categorical_crossentropy** loss takes a vector of logits and a True index and returns a scalar loss for each example.\n",
    "\n",
    "This loss is equal to the negative log probability of the true class: It is zero if the model is sure of the correct class.\n",
    "\n",
    "$$ L = \\sum_i ( y_i \\ln z_i )+ (1-y_i) \\ln (1-z_i) $$\n",
    "where z is the output of node $i$.\n",
    "\n",
    "\n",
    "\n",
    "#### NOTE\n",
    "* If your targets are **one-hot encoded**, use **categorical_crossentropy**. Examples of one-hot encodings: [1,0,0] or [0,1,0]\n",
    "\n",
    "* If your targets are integers, use **sparse_categorical_crossentropy**. Examples of integer encodings (for the sake of completion).\n",
    "\n",
    "##### Another Note\n",
    "Use sparse categorical crossentropy when your classes are mutually exclusive (e.g. when each sample belongs exactly to one class) and categorical crossentropy when one sample can have multiple classes or labels are soft probabilities (like [0.5, 0.3, 0.2]).\n",
    "\n",
    "#### Loss initial value = 2.3\n",
    "This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf.math.log(1/10) ~= 2.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View our initial loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "loss_fn(Y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define our loss function \n",
    "\n",
    "We will be using the Categorical cross-entropy, described above.\n",
    "\n",
    "### define our optimizer\n",
    "We will use stochast gradient descent with the following parameters\n",
    "* Learning rate $\\alpha = 0.1$\n",
    "* Momentum $\\beta = 0.9$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#define our optimizer\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=False, name='SGD')\n",
    "#\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy', #need to define our loss function\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the network to be useful, we need to actually train it, so that the weights are actually meaningful, non-random values. As we mentioned before, we'll use the network to make predictions, then compare the predictions agains the ground truth. But how do we compare the predictions against the ground truth? We'll need a few more things. In particular, we need to:\n",
    "\n",
    "1. Specifying a \"reward\" or a **loss** (negative reward) that judges how good or bad the prediction was, compared to the **ground truth** actual value.\n",
    "2. Specifying an **optimizer** that tunes the parameters to improve the reward or loss.\n",
    "\n",
    "Choosing a good **loss function**  L(actual,predicted)  for a problem is not a trivial task. The definition of a loss function also transforms a **classification** problem into an **optimization** problem: what set of parameters minimizes the loss (or maximizes the reward) across the training examples?\n",
    "\n",
    "Turning a learning problem into an optimization problem is actually a very subtle but important step in many machine learning tools, because it allows us to use tools from mathematical optimization.\n",
    "\n",
    "That there are **optimizers** that can tune the network parameters for us is also really, really cool. Unfortunately, we won't talk much about optimizers and how they work in this course. You should know though that these optimizers are what makes machine learning work at all.\n",
    "\n",
    "For now, we will choose a standard loss function for a **binary classification** problem: the **binary cross-entropy loss**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We will train this network to perform a digit recognition task. That is, we will use the MNIST dataset of hand-written digits.\n",
    "\n",
    "1. Predict. Show the network pictures of digits, one by one.  Then we see what the network predicts.\n",
    "3. Loss. Check the loss function for that example digit, comparing the network prediction against the ground truth\n",
    "4. Optimize through grandient descent. We make a small update to the parameters to try and improve the loss for that digit.\n",
    "5. Repeat. Continue doing this many many times.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model.fit method adjusts the model parameters to minimize the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tstart = tf.timestamp()\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=epochs,batch_size=batch_size,\n",
    "                    validation_split = 0.2) # Data for evaluation\n",
    "total_time = tf.timestamp() - tstart\n",
    "print(\"total time %3.3f seconds\"%total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model.evaluate method checks the models performance, usually on a \"Validation-set\" or \"Test-set\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(X_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image classifier is now trained to >97% accuracy on this dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, to_file='model.png', show_shapes=True,  show_dtype=False,\n",
    "    rankdir='TB', expand_nested=False, dpi=150, show_layer_names=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simple NN network has the above architecture.  You can see even this relatively small network has a large number of parameters: **79,510**.  So overfitting is always an concern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model.evaluate(X_test, Y_test, batch_size=128,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#we will use this a lot, so lets make a function\n",
    "def printAccuracy(history,results_test):\n",
    "    print(\"train loss %.5f \\t train acc: %.5f\"%(history.history['loss'][-1],history.history['accuracy'][-1]))\n",
    "    print(\"valid loss %.5f \\t valid acc: %.5f\"%(history.history['val_loss'][-1],history.history['val_accuracy'][-1]))\n",
    "    print(\"test loss  %.5f \\t test acc:  %.5f\"%(results_test[0],results_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printAccuracy(history,results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training loss per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will do this a lot, so lets make a function for this\n",
    "def plot_result(history,results_test):\n",
    "    # Get training and validation histories\n",
    "    training_acc = history.history['accuracy']\n",
    "    val_acc      = history.history['val_accuracy']\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_acc) + 1)\n",
    "    # Visualize loss history\n",
    "    plt.plot(epoch_count, training_acc, 'b-o',label='Training')\n",
    "    plt.plot(epoch_count, val_acc, 'r--',label='Validation')\n",
    "    plt.plot(epoch_count, results_test[1]*np.ones(len(epoch_count)),'k--',label='Test')\n",
    "    plt.legend()\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_result(history,results_test)\n",
    "plt.title(\"MNIST 1-hidden layer in %3.2f s\"%(total_time)) #overwrite the title \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see the plot for train, validation, and test data. Lets make a few quick observations to better know what is happening when we train the data set.\n",
    "* The final training accuracy is very high, the network is learning the data - and it looks like its overtraining.  If we keep going and our network is large enough, we expect this loss to go to one.  Its memorizing our training data.\n",
    "* The final validation and test accuracies are similar.  If its not, then its likely we aren't training long enough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict classes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_hat = np.argmax(model.predict(X_test), axis=-1)\n",
    "pd.crosstab(y_hat, y_test) #note lower case is the numeric value, upper case (Y_test) is the one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misidentified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_hat = np.argmax(model.predict(X_test), axis=-1)\n",
    "test_wrong = [im for im in zip(X_test,y_hat,y_test) if im[1] != im[2]]\n",
    "#=====\n",
    "#plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "for ind, val in enumerate(test_wrong[:100]):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(10, 10, ind + 1)\n",
    "    im = 1 - val[0].reshape((28,28))\n",
    "    plt.axis(\"off\")\n",
    "    plt.text(0, 0, val[2], fontsize=14, color='blue')\n",
    "    plt.text(8, 0, val[1], fontsize=14, color='red')\n",
    "    plt.imshow(im, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total number of connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name, \"in:\",layer.input_shape,\"out:\",layer.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wsave = model.get_weights()\n",
    "model.set_weights(Wsave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "\n",
    "During training, some number of layer outputs are randomly ignored or “dropped out.” This has the effect of making the layer look-like and be treated-like a layer with a different number of nodes and connectivity to the prior layer. In effect, each update to a layer during training is performed with a different “view” of the configured layer.\n",
    "\n",
    "Dropout has the effect of making the training process noisy, forcing nodes within a layer to take on more or less responsibility for the inputs.\n",
    "\n",
    "Dropout may be implemented on any or all hidden layers in the network as well as the visible or input layer. It is not used on the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([              # model type\n",
    "  tf.keras.layers.Flatten(input_shape=X_train[1].shape),  # input layer\n",
    "  tf.keras.layers.Dense(100, activation='relu'),  # hidden layer\n",
    "  tf.keras.layers.Dropout(0.2),                   # Dropout helps reduce overfitting \n",
    "  tf.keras.layers.Dense(10),                      # output to each class, could just stop here\n",
    "  tf.keras.layers.Softmax()                       # convert to probability\n",
    "])\n",
    "#define our optimizer\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=False, name='SGD')\n",
    "#\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy', #need to define our loss function\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstart = tf.timestamp()\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=epochs,batch_size=batch_size,\n",
    "                    validation_split = 0.2) # Data for evaluation\n",
    "total_time = tf.timestamp() - tstart\n",
    "print(\"total time %3.3f seconds\"%total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = model.evaluate(X_test, Y_test, batch_size=128,verbose=0)\n",
    "printAccuracy(history,results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_result(history,results_test)\n",
    "plt.title(\"MNIST 1-hidden layer, with dropout, in %3.2f s\"%(total_time)) #overwrite the title \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Without dropout, the test accuracy was 97.8%. \n",
    "* With dropout, we are slightly down to 97.6%.  However, the training accuracy is now nearly the same as the test, which is a good sign that we are not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One more thing: initialization\n",
    "Lets try once more, this time we will **initialize all weights** to **zero** and then train.  \n",
    "For more on initializers (and there are many options), check out [https://www.tensorflow.org/api_docs/python/tf/keras/initializers](https://www.tensorflow.org/api_docs/python/tf/keras/initializers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([                      # model type\n",
    "  tf.keras.layers.Flatten(input_shape=X_train[1].shape),  # input layer\n",
    "  tf.keras.layers.Dense(100, activation='relu',\n",
    "                        kernel_initializer='zeros',       # some options: 'random_uniform','zeros', and 'glorot_normal' \n",
    "                        bias_initializer='zeros'),        # hidden layer with relu activation, start w/ zeros  \n",
    "  tf.keras.layers.Dense(10),                              # output to each class, leave this with small initial weights\n",
    "  tf.keras.layers.Softmax()                               # softmax (probability) activation\n",
    "])\n",
    "#define our optimizer\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=False, name='SGD')\n",
    "#\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy', #need to define our loss function\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tstart = tf.timestamp()\n",
    "history = model.fit(X_train, Y_train, \n",
    "                    epochs=epochs,batch_size=batch_size,\n",
    "                    validation_split = 0.2) # Data for evaluation\n",
    "total_time = tf.timestamp() - tstart\n",
    "print(\"total time %3.3f seconds\"%total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_test = model.evaluate(X_test, Y_test, batch_size=128,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printAccuracy(history,results_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
