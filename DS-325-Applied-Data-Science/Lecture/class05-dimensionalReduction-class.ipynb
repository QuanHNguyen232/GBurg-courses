{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science 325\n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "* Students will learn the motivation for dimensionality reduction techniques.\n",
    "* Students will be exposed to two algorithmic approaches to dimensionality reduction: principal component analysis (PCA) and t-SNE\n",
    "* Students will practice the application of PCA with a plot for gaining visual insight into higher-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns; \n",
    "sns.axes_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA v LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_iris = pd.read_csv('http://public.gettysburg.edu/~jpuckett/ds325/data/iris.csv')\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select the features and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['SepalLength','SepalWidth','PetalLength','PetalWidth']\n",
    "# Separating out the features\n",
    "X = df_iris.loc[:, features].values\n",
    "# Separating out the target\n",
    "y = df_iris.loc[:,['Species']].values\n",
    "class_names = np.unique(y)\n",
    "# Standardizing the features\n",
    "X_std = StandardScaler().fit_transform(X) #why is it so important to scale before PCA, see hw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_std) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8.1,5),dpi=100)\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "targets = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "for target in (class_names):\n",
    "    inn = (y == target).ravel()\n",
    "    ax.scatter(X_pca[inn,0],X_pca[inn,1],s=30)\n",
    "ax.legend(class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(n_components=2)\n",
    "X_lda = lda.fit_transform(X_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8.1,5),dpi=100)\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('LD1', fontsize = 15)\n",
    "ax.set_ylabel('LD2', fontsize = 15)\n",
    "for target in (class_names):\n",
    "    inn = (y == target).ravel()\n",
    "    ax.scatter(X_lda[inn,0],X_lda[inn,1],s=30)\n",
    "ax.legend(class_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on digits data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits, d_labels = load_digits(return_X_y=True)\n",
    "x = StandardScaler().fit_transform(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the data consists of 8×8 pixel images, meaning that they are 64-dimensional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,5),dpi=75)\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in range(1, 31):\n",
    "    ax = fig.add_subplot(3, 10, i)\n",
    "    plt.imshow(digits[i].reshape(8,8),cmap='gray')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain some intuition into the relationships between these points, we can use PCA to project them to a more manageable number of dimensions, say two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(2)  # project from 64 to 2 dimensions\n",
    "projected = pca.fit_transform(x)\n",
    "print(digits.data.shape)\n",
    "print(projected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the first two principal components of each point to learn about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8.1,5),dpi=75)\n",
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=d_labels, edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap('Spectral', 10))\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall what these components mean: the full data is a 64-dimensional point cloud, and these points are the projection of each data point along the directions with the largest variance. Essentially, we have found the optimal stretch and rotation in 64-dimensional space that allows us to see the layout of the digits in two dimensions, and have done this in an unsupervised manner—that is, without reference to the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the components mean?\n",
    "We can go a bit further here, and begin to ask what the reduced dimensions mean. This meaning can be understood in terms of combinations of basis vectors. For example, each image in the training set is defined by a collection of 64 pixel values, which we will call the vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA can be thought of as a process of choosing optimal basis functions, such that adding together just the first few of them is enough to suitably reconstruct the bulk of the elements in the dataset. The principal components, which act as the low-dimensional representation of our data, are simply the coefficients that multiply each of the elements in this series. This figure shows a similar depiction of reconstructing this digit using the mean plus the first eight PCA basis functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the pixel basis, the PCA basis allows us to recover the salient features of the input image with just a mean plus eight components! The amount of each pixel in each component is the corollary of the orientation of the vector in our two-dimensional example. This is the sense in which PCA provides a low-dimensional representation of the data: it discovers a set of basis functions that are more efficient than the native pixel-basis of the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the number of components\n",
    "\n",
    "A vital part of using PCA in practice is the ability to estimate how many components are needed to describe the data. This can be determined by looking at the cumulative explained variance ratio as a function of the number of components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca = PCA().fit(x)\n",
    "fig = plt.figure(figsize = (8.1,5),dpi=75)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This curve quantifies how much of the total, 64-dimensional variance is contained within the first $N$ components. For example, we see that with the digits the first 10 components contain approximately 75% of the variance, while you need around 50 components to describe close to 100% of the variance.\n",
    "\n",
    "Here we see that our two-dimensional projection loses a lot of information (as measured by the explained variance) and that we'd need about 20 components to retain 90% of the variance. Looking at this plot for a high-dimensional dataset can help you understand the level of redundancy present in multiple observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### de-noising\n",
    "Now lets add some random noise to create a noisy dataset, and re-plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(325)\n",
    "noisy = np.random.normal(digits, 2)\n",
    "fig = plt.figure(figsize = (10,5),dpi=75)\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in range(1, 31):\n",
    "    ax = fig.add_subplot(3, 10, i)\n",
    "    plt.imshow(noisy[i].reshape(8,8),cmap='gray')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clear by eye that the images are noisy, and contain spurious pixels. Let's train a PCA on the noisy data, requesting that the projection preserve 50% of the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.50).fit(noisy)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here 50% of the variance amounts to 12 principal components. Now we compute these components, and then use the inverse of the transform to reconstruct the filtered digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca.transform(noisy)\n",
    "filtered = pca.inverse_transform(components)\n",
    "fig = plt.figure(figsize = (10,5),dpi=75)\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in range(1, 31):\n",
    "    ax = fig.add_subplot(3, 10, i)\n",
    "    plt.imshow(filtered[i].reshape(8,8),cmap='gray')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This signal preserving/noise filtering property makes PCA a very useful feature selection routine—for example, rather than training a classifier on very high-dimensional data, you might instead train the classifier on the lower-dimensional representation, which will automatically serve to filter out random noise in the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, PCA has a \"bunching\" problem with many of the other digits overlapping one another in 2 dimensions.\n",
    "\n",
    "t-SNE is an algorithm that seeks to \"unfold\" points in high dimensions so as to project similar points near to one another in 2D, while holding different points apart. Let us observe how \n",
    "t-SNE performs with the same data for different \"perplexity\" parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perplexities = [5, 30, 50]  # 30 is the default\n",
    "fig = plt.figure(figsize = (15,5),dpi=75)\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "for i in range(len(perplexities)):\n",
    "    p = perplexities[i]\n",
    "    tsne = TSNE(random_state=0, perplexity=p)\n",
    "    projected = tsne.fit_transform(digits)  # project from 64 to 2 dimensions\n",
    "    ax = fig.add_subplot(1, 3, i+1)\n",
    "    im=ax.scatter(projected[:, 0], projected[:, 1],\n",
    "                c=d_labels, edgecolor='none', alpha=0.5,\n",
    "                cmap=plt.cm.get_cmap('Spectral', 10))  # Note: 'Spectral' must now be capitalized, unlike lowercase 'spectral' in text.\n",
    "    ax.set_title('perplexity=%d'%p)\n",
    "    ax.set_xlabel('component 1')\n",
    "    if (i==0):\n",
    "        ax.set_ylabel('component 2')\n",
    "fig.subplots_adjust(bottom=0.1, top=0.9, left=0.1, right=0.88,\n",
    "                    wspace=0.15, hspace=0.02)\n",
    "# add an axes, lower left corner in [0.83, 0.1] measured in figure coordinate with axes width 0.02 and height 0.8\n",
    "cb_ax = fig.add_axes([0.9, 0.1, 0.02, 0.8])\n",
    "cbar = fig.colorbar(im, cax=cb_ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how sensitive t-SNE is to its perplexity parameter. While it achieves good separation of digits data (without digits target values) using different perplexity values, you will note that the spatial relationships change from one value to the next. Some strong similarity relationships are reflected in all runs, but take a moment to observe which digits are deemed most similar to one another in the different plots above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As unsupervised learning tools, dimensionality reduction can help us gain better insight into high-dimensional data in many application areas.\n",
    "\n",
    "Postscript: We have been sticking fairly close to what is available in numpy, pandas, matplotlib, and sklearn. A newer manifold learning method called UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction has gained in popularity for high-dimensional applications (e.g. for single cell genomics)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
