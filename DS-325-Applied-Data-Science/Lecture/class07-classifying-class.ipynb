{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science 325\n",
    "\n",
    "## Clustering\n",
    "\n",
    "### Learning Objectives:\n",
    "\n",
    "* Students will learn the motivation for classification techniques.\n",
    "* Students will be exposed to two algorithmic approaches to classification: SVM and kNN\n",
    "* Students will practice the application of these techniques and visualize their results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this week's project is to build simple classifiers that can be trained from data. In particular, you will implement a K-nearest-neighbor classifier, Support vector machine and Naive Bayes classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier #knn\n",
    "from sklearn.svm import SVC                        #SVM \"Support vector classifier\"\n",
    "from sklearn import naive_bayes                    #naive bayes classifier\n",
    "import seaborn as sns; \n",
    "sns.axes_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Information:\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link]\n",
    "\n",
    "Separating plane described above was obtained using Multisurface Method-Tree (MSM-T), a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\n",
    "\n",
    "[https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading Data set\n",
    "web_addr = 'http://public.gettysburg.edu/~jpuckett/ds325/data/'\n",
    "df = pd.read_csv(web_addr+\"breast_cancer_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute Information:\n",
    "0) id \n",
    "1) Diagnosis (M = malignant, B = benign), we will convert this into (Malignant) = 1 and B (Benign) = 0\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter)\n",
    "b) texture (standard deviation of gray-scale values)\n",
    "c) perimeter\n",
    "d) area\n",
    "e) smoothness (local variation in radius lengths)\n",
    "f) compactness (perimeter^2 / area - 1.0)\n",
    "g) concavity (severity of concave portions of the contour)\n",
    "h) concave points (number of concave portions of the contour)\n",
    "i) symmetry\n",
    "j) fractal dimension (\"coastline approximation\" - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null / nan. We do not have missing values, Great!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop useless data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis = 1, inplace = True)\n",
    "df.drop('Unnamed: 32', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many counts for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['diagnosis'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encode the target 'diagnosis'.**\n",
    "\n",
    "You can use something like:\n",
    "\n",
    "\n",
    "<code>def diagnosis_value(diagnosis):\n",
    "    if diagnosis == 'M':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['diagnosis'] = df['diagnosis'].apply(diagnosis_value)\n",
    "</code>\n",
    "\n",
    "Probably better to use built-in functions like below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['diagnosis']\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "classes = le.classes_\n",
    "y_enc=le.transform(y)\n",
    "df['diagnosis_enc'] = le.transform(y) #now 1=M; 0=B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split our dataset into mean and worst and a small "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df[['radius_mean',  'perimeter_mean', 'area_mean', 'smoothness_mean','texture_mean',\n",
    "               'compactness_mean','concavity_mean', 'symmetry_mean','fractal_dimension_mean','diagnosis_enc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations: \n",
    "View Heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))  # on this line I just set the size of figure to 12 by 10.\n",
    "p=sns.heatmap(df.corr(), annot=False, vmin=-1, vmax=1,cmap =\"coolwarm\");  # seaborn has very simple solution for heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean only correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df_mean.corr(), annot=False, vmin=-1, vmax=1,cmap =\"coolwarm\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view distribution of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_var = [\"radius_mean\",\"area_mean\",\"perimeter_mean\",\"texture_mean\",\"smoothness_mean\",\"symmetry_mean\"] \n",
    "ncols = 3\n",
    "fig, axs = plt.subplots(nrows=2, ncols=ncols, figsize=(15, 5))\n",
    "axs = axs.flatten()\n",
    "for i in range(len(col_var)):\n",
    "    plt.sca(axs[i])\n",
    "    sns.kdeplot(data=df_mean, x=col_var[i],hue='diagnosis_enc',shade=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skewness\n",
    "* A left-skewed distribution has a long left tail. Left-skewed distributions are also called negatively-skewed distributions. That’s because there is a long tail in the negative direction on the number line. The mean is also to the left of the peak.\n",
    "\n",
    "* A right-skewed distribution has a long right tail. Right-skewed distributions are also called positive-skew distributions. That’s because there is a long tail in the positive direction on the number line. The mean is also to the right of the peak.\n",
    "\n",
    "\n",
    "##### to learn more about skewness\n",
    "https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/skewed-distribution/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection/Feature Engineering\n",
    "We are just going to focus on **df_mean** which contains only the mean of the radius, perimeter, area, smoothness, texture. \n",
    "\n",
    "We can see a strong correlation between some features such as **radius** & **area**, we can easily remove one of them. Since, the **radius_mean** has a more correlation with the target varaible (**diagnosis**), we keep it.\n",
    "\n",
    "Also we can see a strong correlation between two features (**perimeter_mean**, **radius_mean**) and they are another twins. Therfore we can remove radius_mean.  \n",
    "\n",
    "While not as clear, **compactness_mean** and **concavity_mean** are also highly correlated.  We'll remove concavity_mean as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "plt.sca(axs[0])\n",
    "sns.scatterplot(x = 'radius_mean', y = 'area_mean', hue = 'diagnosis_enc', data = df_mean)\n",
    "plt.sca(axs[1])\n",
    "sns.scatterplot(x = 'radius_mean', y = 'perimeter_mean', hue = 'diagnosis_enc', data = df_mean)\n",
    "plt.sca(axs[2])\n",
    "sns.scatterplot(x = 'compactness_mean', y = 'concavity_mean', hue = 'diagnosis_enc', data = df_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncorrelated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "plt.sca(axs[0])\n",
    "sns.scatterplot(x = 'smoothness_mean', y = 'texture_mean', hue = 'diagnosis_enc', data = df_mean)\n",
    "plt.sca(axs[1])\n",
    "sns.scatterplot(x = 'smoothness_mean', y = 'symmetry_mean', hue = 'diagnosis_enc', data = df_mean)\n",
    "plt.sca(axs[2])\n",
    "sns.scatterplot(x = 'smoothness_mean', y = 'fractal_dimension_mean', hue = 'diagnosis_enc', data = df_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = df_mean.drop(df_mean[['perimeter_mean','area_mean','concavity_mean']], axis = True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the dimensionality to 2 dimensionals, for visualization\n",
    "\n",
    "This is more for our later visualualization and to help with interpretability.   We will revist the classification using the **mean** dataset after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the strength of each feature onto the principal components\n",
    "X_features = df3.drop(['diagnosis_enc'], axis=1)\n",
    "X_feat_std = StandardScaler().fit_transform(X_features) \n",
    "pca = PCA(n_components=4)\n",
    "x_new = pca.fit_transform(X_feat_std)\n",
    "fig= plt.figure(figsize=(5,3),dpi=100)\n",
    "ax = sns.heatmap(pca.components_,annot=True,cmap='coolwarm',\n",
    "                 yticklabels=[ \"PCA\"+str(x) for x in range(1,pca.n_components_+1)],\n",
    "                 xticklabels=list(X_features.columns),vmin=-1,vmax=1)\n",
    "plt.yticks(rotation=0);\n",
    "ax.axis('equal');plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#determine top 2 features for first two PCA components\n",
    "nPCA = 2\n",
    "X_features = df3.drop(['diagnosis_enc'], axis=1)\n",
    "X_feat_std = StandardScaler().fit_transform(X_features) \n",
    "featureNames = X_features.columns\n",
    "pca = PCA(n_components=nPCA).fit(X_feat_std)\n",
    "X_pca = pca.transform(X_feat_std)\n",
    "most_important = [np.abs(pca.components_[i]).argmax() for i in range(nPCA)]\n",
    "most_important_names = [featureNames[most_important[i]] for i in range(nPCA)]\n",
    "print(most_important_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make our dataset.  \n",
    "* target is the **diagnosis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our mean dataset\n",
    "y = df3['diagnosis_enc']\n",
    "X = df3.drop(['diagnosis_enc'], axis=1)\n",
    "X_std = StandardScaler().fit_transform(X) \n",
    "# our 2 parameter dataset\n",
    "col2 = ['compactness_mean', 'radius_mean']\n",
    "X2 = df3[col2]\n",
    "X2_std = StandardScaler().fit_transform(X2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make our test/train/validate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid     = train_test_split(X_std, y,test_size=0.3, random_state=325)\n",
    "X2_train, X2_valid, y2_train, y2_valid = train_test_split(X2_std, y,test_size=0.3, random_state=325)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with **k=1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting decision boundaries for 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictCLFmap(X,clf,h=0.02):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))    \n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    return Z,xx,yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_neighbors=1\n",
    "knn2 = KNeighborsClassifier(k_neighbors)\n",
    "knn2.fit(X2_train,y2_train)\n",
    "Z,xx,yy = predictCLFmap(X2_train,knn2,h=0.05)\n",
    "#plot\n",
    "fig = plt.figure(figsize=(8.1,5),dpi=100);\n",
    "plt.contourf(xx,yy,Z,cmap=plt.cm.Blues, alpha=0.8)\n",
    "col = ['r','k']\n",
    "markers = ['o', 's']\n",
    "for i in range(2): #2 clusters\n",
    "    iny = y_valid==i\n",
    "    plt.scatter(X2_valid[iny, 0], X2_valid[iny, 1], color=col[i],marker=markers[i],s=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn2.predict(X2_valid)\n",
    "cm = confusion_matrix(y2_valid, y_pred)\n",
    "acc = accuracy_score(y2_valid, y_pred)\n",
    "#plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey='row')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[0])\n",
    "axes[0].set_title('counts')\n",
    "cmd = ConfusionMatrixDisplay(cm/np.sum(cm[:]),display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[1])\n",
    "axes[1].set_title('normalized')\n",
    "fig.suptitle('kNN, $X_{dim=2}$, k=1, accuracy=%2.3f'%(acc), fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validate to find best k\n",
    "Using **gridsearchCV**\n",
    "Allows you to define a grid of parameters that will be searched using K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, verbose = 0, cv=3, scoring='accuracy');\n",
    "grid.fit(X2_train, y2_train);\n",
    "#\n",
    "print('kNN best param = ',grid.best_params_)\n",
    "kscoreM = grid.cv_results_['mean_test_score']\n",
    "kscoreS = grid.cv_results_['std_test_score']\n",
    "knnBest = grid.best_estimator_\n",
    "k_cv = grid.best_params_['n_neighbors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how does knn do on our test dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result Visualisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8.1,5))\n",
    "plt.errorbar(k_range,kscoreM,kscoreS,marker='o',label='Train Score',capsize=5, elinewidth=2, markeredgewidth=2)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('CV mean score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation shows k=29 has the highest test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z,xx,yy = predictCLFmap(X2_train,knnBest,h=0.05)\n",
    "#plot\n",
    "fig = plt.figure(figsize=(8.1,5),dpi=100);\n",
    "plt.contourf(xx,yy,Z,cmap=plt.cm.Blues, alpha=0.8)\n",
    "col = ['r','k']\n",
    "markers = ['o', 's']\n",
    "for i in range(2): #2 clusters\n",
    "    iny = y_valid==i\n",
    "    plt.scatter(X2_valid[iny, 0], X2_valid[iny, 1], color=col[i],marker=markers[i],s=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = knnBest.predict(X2_valid)\n",
    "cm = confusion_matrix(y2_valid, y_pred)\n",
    "acc = accuracy_score(y2_valid, y_pred)\n",
    "#plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey='row')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[0])\n",
    "axes[0].set_title('counts')\n",
    "cmd = ConfusionMatrixDisplay(cm/np.sum(cm[:]),display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[1])\n",
    "axes[1].set_title('normalized')\n",
    "fig.suptitle('kNN, $X_{dim=2}$, k=%d, accuracy=%2.3f'%(k_cv,acc), fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 90 true positives and 61 true negatives.  There are 20 misidentified test examples.\n",
    "\n",
    "How to read:\n",
    "* The diagonal elements show the number of correct classifications for each class.\n",
    "* The off-diagonal elements provides the misclassifications: for example, 4 of the benign were misclassified as malignant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN with all 'mean' features\n",
    "\n",
    "#### cross validate to find best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1, 31))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, verbose = 0, cv=3, scoring='accuracy');\n",
    "grid.fit(X_train, y_train);\n",
    "#\n",
    "print('kNN best param = ',grid.best_params_)\n",
    "kscoreM = grid.cv_results_['mean_test_score']\n",
    "kscoreS = grid.cv_results_['std_test_score']\n",
    "knnBest = grid.best_estimator_\n",
    "k_cv = grid.best_params_['n_neighbors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8.1,5))\n",
    "plt.errorbar(k_range,kscoreM,kscoreS,marker='o',label='Train Score',capsize=5, elinewidth=2, markeredgewidth=2)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('CV mean score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knnBest.predict(X_valid)\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "acc = accuracy_score(y_valid, y_pred)\n",
    "#plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey='row')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[0])\n",
    "axes[0].set_title('counts')\n",
    "cmd = ConfusionMatrixDisplay(cm/np.sum(cm[:]),display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[1])\n",
    "axes[1].set_title('normalized')\n",
    "fig.suptitle('kNN, $X_{mean}$, k=%d, accuracy=%2.3f'%(k_cv,acc), fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a large improvement in the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's switch gears here to use an SVM.  \n",
    "\n",
    "SVM training depends on dozens of parameters:\n",
    "\n",
    "* C parameter - greater the missclassification penalty, slower the process\n",
    "* kernel - more complicated the kernel, slower the process (rbf is the most complex from the predefined ones)\n",
    "* data size/dimensionality - again, the same rule\n",
    "\n",
    "We'll start with a small **C = 0.01**, and a linear kernel and our "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel='linear', C=0.01)\n",
    "svc_model.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the support vectors. We'll only view the first 5 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model.support_vectors_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z,xx,yy = predictCLFmap(X2_train,svc_model,h=0.05)\n",
    "#plot\n",
    "fig = plt.figure(figsize=(8.1,5),dpi=100);\n",
    "plt.contourf(xx,yy,Z,cmap=plt.cm.Blues, alpha=0.8)\n",
    "col = ['r','k']\n",
    "markers = ['o', 's']\n",
    "for i in range(2): #2 clusters\n",
    "    iny = y_valid==i\n",
    "    plt.scatter(X2_valid[iny, 0], X2_valid[iny, 1], color=col[i],marker=markers[i],s=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = svc_model.predict(X2_valid)\n",
    "cm = confusion_matrix(y2_valid, y_pred)\n",
    "acc = accuracy_score(y2_valid, y_pred)\n",
    "#plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey='row')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[0])\n",
    "axes[0].set_title('counts')\n",
    "cmd = ConfusionMatrixDisplay(cm/np.sum(cm[:]),display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[1])\n",
    "axes[1].set_title('normalized')\n",
    "fig.suptitle('SVM, $X_{dim=2}$, C=0.01, accuracy=%2.3f'%acc, fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridsearchCV\n",
    "\n",
    "Use gridsearchCV to find the best C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.01,0.02,0.05,0.07,0.08,0.1,0.2,0.5,0.9,1,10,20],               \n",
    "              'kernel': ['linear']}  \n",
    "grid = GridSearchCV(SVC(), param_grid, verbose = 0, cv=3, scoring='accuracy');\n",
    "# fitting the model for grid search \n",
    "grid.fit(X2_train, y2_train);\n",
    "svmBest = grid.best_estimator_\n",
    "C_cv = grid.best_params_['C']\n",
    "CscoreM = grid.cv_results_['mean_test_score']\n",
    "CscoreS = grid.cv_results_['std_test_score']\n",
    "svmBest = grid.best_estimator_\n",
    "print(grid.best_estimator_) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8.1,5))\n",
    "plt.plot(param_grid['C'],CscoreM,marker='o')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('CV mean score')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svmBest.predict(X2_valid)\n",
    "cm = confusion_matrix(y2_valid, y_pred)\n",
    "acc = accuracy_score(y2_valid, y_pred)\n",
    "#plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey='row')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[0])\n",
    "axes[0].set_title('counts')\n",
    "cmd = ConfusionMatrixDisplay(cm/np.sum(cm[:]),display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[1])\n",
    "axes[1].set_title('normalized')\n",
    "fig.suptitle('SVM, $X_{dim=2}$, C=%3.3f, accuracy=%2.3f'%(C_cv,acc), fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM is not bad, but not as good as the kNN.  Let's try to use a non-linear kernel, 'rbf'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear kernel, rbf.\n",
    "\n",
    "RBF has two parameters\n",
    "* C = softness parameter, regularization parameter. The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared L2 penalty.\n",
    "* $\\gamma$, Kernel coefficient, smaller will be more linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_modelRBG = SVC(kernel='rbf', C=1, gamma=0.01,random_state = 0)\n",
    "svc_modelRBG.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z,xx,yy = predictCLFmap(X2_train,svc_modelRBG,h=0.05)\n",
    "#plot\n",
    "fig = plt.figure(figsize=(8.1,5),dpi=100);\n",
    "plt.contourf(xx,yy,Z,cmap=plt.cm.Blues, alpha=0.8)\n",
    "col = ['r','k']\n",
    "markers = ['o', 's']\n",
    "for i in range(2): #2 clusters\n",
    "    iny = y_valid==i\n",
    "    plt.scatter(X2_valid[iny, 0], X2_valid[iny, 1], color=col[i],marker=markers[i],s=50);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = svc_modelRBG.predict(X2_valid)\n",
    "cm = confusion_matrix(y2_valid, y_pred)\n",
    "acc = accuracy_score(y2_valid, y_pred)\n",
    "#plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey='row')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[0])\n",
    "axes[0].set_title('counts')\n",
    "cmd = ConfusionMatrixDisplay(cm/np.sum(cm[:]),display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[1])\n",
    "axes[1].set_title('normalized')\n",
    "fig.suptitle('SVM RBF, $X_{dim=2}$, C=1, gamma=0.01, accuracy=%2.3f'%(acc), fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "Here lets use GridSearchCV to help find the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.01,0.02,0.05,0.07,0.08,0.1,0.2,0.5,0.9,1,10,20], \n",
    "              'gamma': [0.001,0.002,0.005,0.01,0.02,0.05,0.1,0.2,0.5,1,2,5,10,20],\n",
    "              'kernel': ['rbf']}  \n",
    "grid = GridSearchCV(SVC(), param_grid, verbose = 0, cv=3, scoring='accuracy');\n",
    "# fitting the model for grid search \n",
    "grid.fit(X2_train, y2_train);\n",
    "svmBest = grid.best_estimator_\n",
    "C_cv = grid.best_params_['C']\n",
    "gamma_cv = grid.best_params_['gamma']\n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = svmBest.predict(X2_valid)\n",
    "cm = confusion_matrix(y2_valid, y_pred)\n",
    "acc = accuracy_score(y2_valid, y_pred)\n",
    "#plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey='row')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[0])\n",
    "axes[0].set_title('counts')\n",
    "cmd = ConfusionMatrixDisplay(cm/np.sum(cm[:]),display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[1])\n",
    "axes[1].set_title('normalized')\n",
    "fig.suptitle(r'SVM, $X_{dim=2}$, RBF kernel, C=%3.1f,$\\gamma$=%3.3f, accuracy=%2.3f'%(C_cv,gamma_cv,acc), fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on 'mean' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.01,0.02,0.05,0.07,0.08,0.1,0.2,0.5,0.9,1,10,20], \n",
    "              'gamma': [0.001,0.002,0.005,0.01,0.02,0.05,0.1,0.2,0.5,1,2,5,10,20],\n",
    "              'kernel': ['rbf']} \n",
    "grid = GridSearchCV(SVC(), param_grid, verbose = 0, cv=3, scoring='accuracy');\n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train);\n",
    "svmBest = grid.best_estimator_\n",
    "C_cv = grid.best_params_['C']\n",
    "gamma_cv = grid.best_params_['gamma']\n",
    "print(grid.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svmBest.predict(X_valid)\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "acc = accuracy_score(y_valid, y_pred)\n",
    "#plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey='row')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[0])\n",
    "axes[0].set_title('counts')\n",
    "cmd = ConfusionMatrixDisplay(cm/np.sum(cm[:]),display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[1])\n",
    "axes[1].set_title('normalized')\n",
    "fig.suptitle(r'SVM, $X_{mean}$, RBF kernel, C=%3.1f,$\\gamma$=%3.3f, accuracy=%2.3f'%(C_cv,gamma_cv,acc), fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = naive_bayes.GaussianNB()\n",
    "gnb.fit(X2_train, y2_train)\n",
    "y_pred = gnb.predict(X2_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y2_valid, y_pred)\n",
    "acc = accuracy_score(y2_valid, y_pred)\n",
    "#plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey='row')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[0])\n",
    "axes[0].set_title('counts')\n",
    "cmd = ConfusionMatrixDisplay(cm/np.sum(cm[:]),display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[1])\n",
    "axes[1].set_title('normalized')\n",
    "fig.suptitle('NaiveBayes, $X_{dim=2}$, accuracy=%2.3f'%acc, fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Naive Bayes score: \",gnb.score(X2_valid, y2_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes with all the 'mean' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = naive_bayes.GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "acc = accuracy_score(y_valid, y_pred)\n",
    "#plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey='row')\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[0])\n",
    "axes[0].set_title('counts')\n",
    "cmd = ConfusionMatrixDisplay(cm/np.sum(cm[:]),display_labels=['benign','malignant']) #1 = M, 0 = B\n",
    "cmd.plot(ax=axes[1])\n",
    "axes[1].set_title('normalized')\n",
    "fig.suptitle('NaiveBayes, $X_{mean}$, accuracy=%2.3f'%acc, fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes score: \",gnb.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction for class of example i=10 and 30 in our validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=10\n",
    "print(\"%d: Class0=%4f, Class1=%4f\"%(i,gnb.predict_proba(X_valid)[i][0],gnb.predict_proba(X_valid)[i][1]))\n",
    "i=30\n",
    "print(\"%d: Class0=%4f, Class1=%4f\"%(i,gnb.predict_proba(X_valid)[i][0],gnb.predict_proba(X_valid)[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The best kNN and SVM performed similarly using the full dataset.  kNN outperformed all for the reduced set of features.\n",
    "\n",
    "#### only 2 features\n",
    "| model | accuracy |\n",
    "| - | - |\n",
    "| kNN k=1 | 0.836 |\n",
    "| kNN k=29 | 0.883 |\n",
    "| SVM C=0.01| 0.848 |\n",
    "| SVM C=2| 0.895 |\n",
    "| SVM RBF C=0.2, $\\gamma$=0.1 | 0.889 |\n",
    "| Naive-bayes | 0.883 |\n",
    "\n",
    "#### all 'mean' features\n",
    "| model | accuracy |\n",
    "| - | - |\n",
    "| kNN k=9 | 0.930 |\n",
    "| SVM RBF C=10, $\\gamma$=0.02 | 0.925 |\n",
    "| Naive-bayes | 0.924 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
