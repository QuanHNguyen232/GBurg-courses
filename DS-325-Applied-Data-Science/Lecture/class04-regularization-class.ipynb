{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science 325\n",
    "\n",
    "## Learning Goal  \n",
    "The goal of this notebook is to get hands-on experience and intuition about linear regression and regularization. We once again emphasize the difference between fitting and predicting. We will see that it is much more difficult to get good out-of-sample performance on a test set (predicting) than it is to get good in-sample performance on the training set (fitting).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares linear regression: \n",
    "\n",
    "For ordinary least square regression (no regularization), we minimize the square loss cost function:\n",
    "\n",
    "$$\n",
    "\\operatorname{min} J(\\theta) = \\operatorname{min} ||X \\theta-\\textbf{y}||_2^2 = \\operatorname{min} (X \\theta-y)^T(X \\theta-y)\n",
    "$$\n",
    "\n",
    "If features $X$ are linearly independent, then there exists unique solution to this problem:\n",
    "\n",
    "$$\n",
    "\\hat{\\theta}= (X^T X)^{-1} X^T y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "In Ridge-Regression, the regularization penalty is taken to be the L2-norm of the parameters\n",
    "\n",
    "$$\n",
    "\\operatorname{min} J_{ridge}(\\theta) = \\operatorname{min} ||X \\theta-y||_2^2 + \\alpha ||\\theta||_2^2\n",
    "$$\n",
    "\n",
    "Notice that the parameter $\\alpha$ controls how much we weigh the fit and regularization term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO ##\n",
    "\n",
    "We will also be interested in the case where the penalty is the L1-norm of the parameters (sum of absolute values of parameters). This is called LASSO.\n",
    "\n",
    "$$\n",
    "\\operatorname{min} J_{lasso}(\\theta) = \\operatorname{min} ||X \\theta-y||_2^2 + \\alpha ||\\theta||_1\n",
    "$$\n",
    "\n",
    "As we discussed in class, LASSO tends to give sparse solution. Below, we're going to explore these ideas a little bit more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; \n",
    "sns.axes_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in our dataset.\n",
    "\n",
    "Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load Advertising dataset\n",
    "web_path = 'http://public.gettysburg.edu/~jpuckett/ds325/data/' #if using data over web\n",
    "df = pd.read_csv(web_path+'auto-mpg.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".describe() generates descriptive statistics that summarize the central tendency, dispersion and shape of a datasetâ€™s distribution, excluding NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean value for mpg is is 23.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".info() prints a concise summary of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Information:\n",
    "\n",
    "1. mpg: continuous\n",
    "2. cylinders: multi-valued discrete\n",
    "3. displacement: continuous\n",
    "4. horsepower: continuous\n",
    "5. weight: continuous\n",
    "6. acceleration: continuous\n",
    "7. model year: multi-valued discrete\n",
    "8. origin: multi-valued discrete\n",
    "9. car name: string (unique for each instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are actually some 'junk' values in horsepower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(df.horsepower.str.isdigit())\n",
    "temp[temp['horsepower']==False]#these are the rows that don't have numerical values for horsepower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see these non-numeric entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df['horsepower'].str.isnumeric()==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets replace those with NaN (not a number)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace('?',np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are 'many' things we can do with the NaN values (like replace with the median or mean).  Here, I'd prefer to drop the rows altogether.  \n",
    "\n",
    "We only lose 6 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert horsepower from strings to float\n",
    "df['horsepower']=df['horsepower'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look for Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "heatmap = sns.heatmap(df.corr(), annot=True,vmin=-1,vmax=1,cmap='coolwarm')\n",
    "# Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are strong correlations between **cylinders**, **displacement** and **weight**.  Additionally, each of these dependent variables have strong negative correlation with the dependent variable **mpg**.  Our end model should keep this in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see pairplot (and histograms) for each variable in the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df, diag_kind='kde');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cylinders and origin only have discrete values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear regression intro\n",
    "Before we dive into how to deal with the strong correlations with our independent variables, lets focus on the **weight** number (x) and **mpg** (y).  From the above table we see the two are clearly (negatively) correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Variables\n",
    "x = np.array(df['weight']) #convert into a numpy array \n",
    "features = df.columns\n",
    "y = np.array(df['mpg'])\n",
    "fig = plt.figure(figsize = (8.1,5),dpi=75)\n",
    "plt.plot(x,y,'bo')\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('mpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ y = \\theta X$\n",
    "$ X = [1 1/x]$\n",
    "$ y = \\theta_0 *1 + \\theta_1 * 1/x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones(x.shape),1./x] #add a column of ones to our x\n",
    "theta_ls = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y) #\n",
    "print('theta0 = %5f'%theta_ls[0]) \n",
    "print('theta1 = %5f'%theta_ls[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(np.min(x),np.max(x),100)\n",
    "yy = theta_ls[0]+theta_ls[1]/xx\n",
    "fig = plt.figure(figsize = (8.1,5),dpi=75)\n",
    "plt.plot(x,y,'bo')\n",
    "plt.plot(xx,yy,'r-')\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('mpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare with curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "# your model definition\n",
    "def f(x, a, b):\n",
    "    return a+b/x\n",
    "# do the fit with some initial values\n",
    "theta_cf, pcov = curve_fit(f, x, y, p0=(1, 1))\n",
    "print('theta0 = %5f'%theta_cf[0])\n",
    "print('theta1 = %5f'%theta_cf[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see these are exactly the same fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yyf = theta_cf[0]+theta_cf[1]/xx\n",
    "fig = plt.figure(figsize = (8.1,5),dpi=75)\n",
    "plt.plot(x,y,'bo')\n",
    "plt.plot(xx,yy,'g-',lw=7,alpha=0.5)\n",
    "plt.plot(xx,yy,'r-')\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('mpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a linear model to fit **mpg** with each of our independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.drop('car name',axis=1)\n",
    "X = df2.drop(['mpg'], axis = 1).astype('float64')\n",
    "y = df[['mpg']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the data into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.3,random_state=1) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the regression and print the coefficient for all independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "print(\"Linear\")\n",
    "for idx, col in enumerate(X_train.columns):\n",
    "    print(\"Coefficient:  %s  \\t=  %4f\"%(col, linear_model.coef_[0][idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The accuracy of the model is %3.3f\"%(linear_model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ridge() function has an alpha argument ( $\\alpha$ , but with a different name!) that is used to tune the model. We'll generate an array of alpha values ranging from very big to very small, essentially covering the full range of scenarios from the null model containing only the intercept, to the least squares fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-3,5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge = Ridge(normalize = True)\n",
    "coefs = []\n",
    "mses = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha = a) #alpha\n",
    "    ridge.fit(X_train, y_train) #fit\n",
    "    coefs.append(ridge.coef_)    #save coefficients\n",
    "    pred = ridge.predict(X_test)  #find predicitions\n",
    "    mses.append(mean_squared_error(y_test, pred) ) #save the MSE\n",
    "#\n",
    "coefs = np.array(coefs).reshape(alphas.shape[0],-1)\n",
    "mses = np.array(mses).reshape(alphas.shape[0],-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the coefficient estimates to be much smaller, in terms of  l2  norm, when a large value of alpha is used, as compared to when a small value of alpha is used. Let's plot and find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8.1, 5),dpi= 75)\n",
    "ax.plot(alphas, np.abs(coefs))\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel(' |weights| ')\n",
    "plt.legend(features)\n",
    "plt.legend(X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets view the $MSE$ score for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8.1, 5),dpi= 75)\n",
    "ax.plot(alphas, mses)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel(r'$MSE$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit a ridge regression model on the training set, and evaluate its MSE on the test set, using $\\alpha=10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge2 = Ridge(alpha = 10,normalize = True)\n",
    "ridge2.fit(X_train, y_train)             # Fit a ridge regression on the training data\n",
    "pred2 = ridge2.predict(X_test)           # Use this model to predict the test data\n",
    "print(pd.Series(ridge2.coef_[0], index = X.columns)) # Print coefficients\n",
    "print(\"R2  = %4f\"%(ridge2.score(X_test,y_test)))\n",
    "print(\"MSE = %4f\"%mean_squared_error(y_test, pred2))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what happens if we use a huge value of alpha, say  $10^5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge3 = Ridge(alpha = 10**5)\n",
    "ridge3.fit(X_train, y_train)             # Fit a ridge regression on the training data\n",
    "pred3 = ridge3.predict(X_test)           # Use this model to predict the test data\n",
    "print(pd.Series(ridge3.coef_[0], index = X.columns)) # Print coefficients\n",
    "print(\"R2  = %4f\"%(ridge3.score(X_test,y_test)))\n",
    "print(\"MSE = %4f\"%mean_squared_error(y_test, pred3))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This big penalty shrinks the coefficients to a very large degree, essentially reducing to a model containing just the intercept. This over-shrinking makes the model more biased, resulting in a higher MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the ridge regression with $\\alpha=10$ do better than regular least squares ( $\\alpha=0$ )?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge4 = Ridge(alpha = 0)\n",
    "ridge4.fit(X_train, y_train)             # Fit a ridge regression on the training data\n",
    "pred4 = ridge4.predict(X_test)            # Use this model to predict the test data\n",
    "print(pd.Series(ridge4.coef_[0], index = X.columns)) # Print coefficients\n",
    "print(\"R2  = %4f\"%(ridge4.score(X_test,y_test)))\n",
    "print(\"MSE = %4f\"%mean_squared_error(y_test, pred4))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of hunting around for the _best_ $\\alpha$, it would be better to use cross-validation to choose the tuning parameter alpha. We can do this using the cross-validated ridge regression function, RidgeCV(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### nice function to find best alpha\n",
    "ridgecv = RidgeCV(alphas = alphas, scoring = 'neg_mean_squared_error')\n",
    "ridgecv.fit(X_train, y_train)\n",
    "print(\"alpha_best = %4f\"%ridgecv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge4 = Ridge(alpha = ridgecv.alpha_)\n",
    "ridge4.fit(X_train, y_train)             # Fit a ridge regression on the training data\n",
    "pred4 = ridge4.predict(X_test)            # Use this model to predict the test data\n",
    "print(pd.Series(ridge4.coef_[0], index = X.columns)) # Print coefficients\n",
    "print(\"R2  = %4f\"%(ridge4.score(X_test,y_test)))\n",
    "print(\"MSE = %4f\"%mean_squared_error(y_test, pred4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that ridge regression with a wise choice of alpha can outperform least squares as well as the null model on the Hitters data set. We now ask whether the lasso can yield either a more accurate or a more interpretable model than ridge regression. In order to fit a lasso model, we'll use the Lasso() function; however, this time we'll need to include the argument max_iter = 10000. \n",
    "\n",
    "We will also need to use **scale** on our **X** data.  \n",
    "* scale normalizes the variable so that we can explore the relative strength of each parameter\n",
    "* this helps us choose a model, but the coefficients no longer have interpretability\n",
    "* after choosing a model, re-run with best **$\\alpha$** without scaling\n",
    "\n",
    "\n",
    "Other than that, we proceed just as we did in fitting a ridge model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(max_iter = 500)\n",
    "coefs = []\n",
    "mses = []\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha = a)\n",
    "    lasso.fit(scale(X_train), y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "    pred = lasso.predict(scale(X_test))\n",
    "    mses.append(mean_squared_error(y_test, pred) )\n",
    "#\n",
    "coefs = np.array(coefs).reshape(alphas.shape[0],-1)\n",
    "mses = np.array(mses).reshape(alphas.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8.1, 5),dpi= 75)\n",
    "ax.plot(alphas, np.abs(coefs))\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel('| weights |')\n",
    "plt.legend(X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets view the $MSE$ score for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8.1, 5),dpi= 75)\n",
    "ax.plot(alphas, mses)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.ylabel(r'$MSE$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the coefficient plot that depending on the choice of tuning parameter, some of the coefficients are exactly equal to zero. We now perform 10-fold cross-validation to choose the best alpha, refit the model, and compute the associated test error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000)\n",
    "lassocv.fit(scale(X_train), np.ravel(y_train))\n",
    "print(\"alpha_best = %4f\"%lassocv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##now use this alpha to train a model\n",
    "lasso.set_params(alpha=lassocv.alpha_)\n",
    "pred5 = lassocv.predict(scale(X_test))\n",
    "print(pd.Series(lassocv.coef_, index = X.columns)) # Print coefficients\n",
    "print(\"R2  = %4f\"%(lassocv.score(scale(X_test),y_test)))\n",
    "print(\"MSE = %4f\"%mean_squared_error(y_test, pred5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this model only uses about 5 non-zeros coefficients for **displacement**, **weight**, **acceleration**, **origin** and **model year**.  Note, the model complexity is lower than OLS (7 coefficients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
