{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "plt.rcParams[\"figure.figsize\"] = [9.708,6]\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#this is our new one\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "# !pip install tensorflow\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving Computer Vision Accuracy using Convolutions\n",
    "\n",
    "In the previous lessons you saw how to do fashion recognition using a Deep Neural Network (DNN) containing three layers -- the input layer (in the shape of the data), the output layer (in the shape of the desired output) and a hidden layer. You experimented with the impact of different sized of hidden layer, number of training epochs etc on the final accuracy.\n",
    "\n",
    "For convenience, here's the entire code again. Run it and take a note of the test accuracy that is printed out at the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "num_classes = 10\n",
    "input_shape = (X_train.shape[1],X_train.shape[2])\n",
    "#normalize the data between 0-1\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test  = X_test.astype( 'float32') / 255\n",
    "#Reshape To Match The Keras's Expectations\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, input_shape[0], input_shape[1])\n",
    "X_test  = X_test.reshape( X_test.shape[0],  1, input_shape[0], input_shape[1])\n",
    "#one hot encoding\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "Y_test  = tf.keras.utils.to_categorical(y_test,  num_classes)\n",
    "#==============\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0],  'test samples')\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce size of data\n",
    "* Note we are doing this because we are interested in how architecture affects the accuracy. \n",
    "* To speed up training and test for your hw, we are decreasing the size of the training data by factor of 2.  \n",
    "* You'll certainly get better results using the whole dataset, but we dont want to spend all our time **training** he **best** model, we'd rather learn how to use CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm= 4\n",
    "X_train=X_train[::mm]\n",
    "Y_train=Y_train[::mm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model architecture\n",
    "\n",
    "We will start with the following model, but will explore how some of the choices here affect our outcome.  \n",
    "\n",
    "Layers for our Network.\n",
    "\n",
    "* **Input layer** - size 784 \n",
    "    * flatten the input image (28x28).\n",
    "* **1 Hidden layers** - with size 100\n",
    "    * Dense (fully connected) network from input layer to these 128 neuron hidden layer.\n",
    "* **Dropout** - 0.2\n",
    "    * randomly sets 20% input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. \n",
    "* **Output layer** - size 10\n",
    "    * Dense layer (fully connected back to the 128 neuron hidden layer). The 10 is the number of classes.  Given an input image, our network should **light** up the corresponding neuron of our target.\n",
    "* **Softmax activation** - convert our output into a probability for each class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs     = 10\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)                             # set our initial seed\n",
    "modelA = tf.keras.models.Sequential([             # model type\n",
    "  tf.keras.layers.Flatten(input_shape=X_train[1].shape),  # input layer\n",
    "  tf.keras.layers.Dense(500, activation='relu'),   # hidden layer\n",
    "  tf.keras.layers.Dropout(0.5),                    # Dropout helps reduce overfitting \n",
    "  tf.keras.layers.Dense(10),                      # output to each class, could just stop here\n",
    "  tf.keras.layers.Softmax()                       # convert to probability\n",
    "])\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True, name='SGD')\n",
    "modelA.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',    #need to define our loss function\n",
    "              metrics=['accuracy'])\n",
    "tstart   = tf.timestamp()\n",
    "historyA = modelA.fit(X_train, Y_train, verbose=1,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split = 0.2) \n",
    "total_time = tf.timestamp() - tstart\n",
    "print(\"total time %3.3f seconds\"%total_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use this a lot, so lets make a function\n",
    "def printAccuracy(history,results_test):\n",
    "    print(\"train loss %.5f \\t train acc: %.5f\"%(history.history['loss'][-1],history.history['accuracy'][-1]))\n",
    "    print(\"valid loss %.5f \\t valid acc: %.5f\"%(history.history['val_loss'][-1],history.history['val_accuracy'][-1]))\n",
    "    print(\"test loss  %.5f \\t test acc:  %.5f\"%(results_test[0],results_test[1]))\n",
    "#we will do this a lot, so lets make a function for this\n",
    "def plot_result(history,results_test):\n",
    "    # Get training and validation histories\n",
    "    training_acc = history.history['accuracy']\n",
    "    val_acc      = history.history['val_accuracy']\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_acc) + 1)\n",
    "    # Visualize loss history\n",
    "    plt.plot(epoch_count, training_acc, 'b-o',label='Training')\n",
    "    plt.plot(epoch_count, val_acc, 'r--',label='Validation')\n",
    "    plt.plot(epoch_count, results_test[1]*np.ones(len(epoch_count)),'k--',label='Test')\n",
    "    plt.legend()\n",
    "    plt.title(\"Training and validation accuracy\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===    \n",
    "results_test = modelA.evaluate(X_test, Y_test, batch_size=128,verbose=0)    \n",
    "printAccuracy(historyA,results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training and test accuracy per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(historyA,results_test)   \n",
    "plt.title(\"MNIST 1-hidden layer, in %3.2f s\"%(total_time)) #overwrite the title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your accuracy is probably about 87% on training and 86% on test...not bad... \n",
    "The best we did last class was about **87%**.\n",
    "\n",
    "But its overtraining a bit and not generalizing as well to the test data.\n",
    "\n",
    "But how do you make that even better? \n",
    "\n",
    "One way is to use something called Convolutions. We're not going to details on Convolutions here, but instead refer to the lecture notes.  \n",
    "* the idea of CNN is that they narrow down the content of the image to focus on specific, distinct, details.\n",
    "\n",
    "If you've ever done image processing using a filter (like this: https://en.wikipedia.org/wiki/Kernel_(image_processing)) then convolutions will look very familiar.\n",
    "\n",
    "In short, you take an array (usually 3x3 or 5x5) and pass it over the image. By changing the underlying pixels based on the formula within that matrix, you can do things like edge detection. So, for example, if you look at the above link, you'll see a 3x3 that is defined for edge detection where the middle cell is 8, and all of its neighbors are -1. In this case, for each pixel, you would multiply its value by 8, then subtract the value of each neighbor. Do this for every pixel, and you'll end up with a new image that has the edges enhanced.\n",
    "\n",
    "This is perfect for computer vision, because often it's features that can get highlighted like this that distinguish one item for another, and the amount of information needed is then much less...because you'll just train on the highlighted features.\n",
    "\n",
    "That's the concept of Convolutional Neural Networks. Add some layers to do convolution before you have the dense layers, and then the information going to the dense layers is more focussed, and possibly more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN: building our first model\n",
    "\n",
    "Next is to define your model. Now instead of the input layer at the top, you're going to add a Convolution. The parameters are:\n",
    "\n",
    "1. The number of convolutions you want to generate. Purely arbitrary, but good to start with something in the order of 32\n",
    "2. The size of the Convolution, in this case a 3x3 grid\n",
    "3. The activation function to use -- in this case we'll use relu, which you might recall is the equivalent of returning x when x>0, else returning 0\n",
    "4. In the first layer, the shape of the input data.\n",
    "\n",
    "\n",
    "### Layers for our Network for CNN model\n",
    "\n",
    "* **Input layer** - size (28x28).\n",
    "* **1 Hidden convolutional layers** - each with size 32 with size (3x3)\n",
    "* **Max Pooling** \n",
    "* **1 Hidden Dense (fully connected) layer** - with size 50\n",
    "* **Dropout** - 0.2\n",
    "* **Output layer** - with **Softmax activation** - convert our output into a probability for each class.\n",
    "\n",
    "\n",
    "You'll follow the Convolution with a MaxPooling layer which is then designed to compress the image, while maintaining the content of the features that were highlighted by the convlution. By specifying (2,2) for the MaxPooling, the effect is to quarter the size of the image. Without going into too much detail here, the idea is that it creates a 2x2 array of pixels, and picks the biggest one, thus turning 4 pixels into 1. It repeats this across the image, and in so doing halves the number of horizontal, and halves the number of vertical pixels, effectively reducing the image by 25%.\n",
    "\n",
    "You can call model.summary() to see the size and shape of the network, and you'll notice that after every MaxPooling layer, the image size is reduced in this way. \n",
    "\n",
    "\n",
    "```\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "```\n",
    "\n",
    "Now flatten the output. After this you'll just have the same DNN structure as the non convolutional version\n",
    "\n",
    "```\n",
    "  tf.keras.layers.Flatten(),\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "The same 128 dense layers, and 10 output layers as in the pre-convolution example:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets compile the model, call the fit method to do the training, and evaluate the loss and accuracy from the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, TensorFlow prefers to have the channels (red,green,blue) last in the ordering of the image. This can be a source of endless headaches trying to get everything the right dimensions in your network.  \n",
    "\n",
    "Your input data should have the shape\n",
    "* **(samples,img_cols,img_rows,img_channels)**\n",
    "\n",
    "However, we have grayscale images, so our **img_channels=1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "num_classes = 10\n",
    "input_shape = (X_train.shape[1],X_train.shape[2])\n",
    "#normalize the data between 0-1\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test  = X_test.astype( 'float32') / 255\n",
    "#Reshape To Match The tf.keras's Expectations for CNNs\n",
    "X_train = X_train.reshape(X_train.shape[0], input_shape[0], input_shape[1],1)\n",
    "X_test  = X_test.reshape( X_test.shape[0],  input_shape[0], input_shape[1],1)\n",
    "#one hot encoding\n",
    "Y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "Y_test  = tf.keras.utils.to_categorical(y_test,  num_classes)\n",
    "#==============\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0],  'test samples')\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce size of data\n",
    "* Note we are doing this because we are interested in how architecture affects the accuracy. \n",
    "* To speed up training and test for your hw, we are decreasing the size of the training data by factor of 4.  \n",
    "* You'll certainly get better results using the whole dataset, but we dont want to spend all our time **training** he **best** model, we'd rather learn how to use CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm= 4\n",
    "X_train=X_train[::mm]\n",
    "Y_train=Y_train[::mm]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your first Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs    = 10\n",
    "batch_size= 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)                             # set our initial seed\n",
    "#===\n",
    "modelB = tf.keras.models.Sequential([             # model type\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu',  \n",
    "                           padding='valid', input_shape=(28,28,1)),#, data_format='channels_first'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),                    # Dropout helps reduce overfitting \n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "#===\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True, name='SGD')\n",
    "modelB.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',    #need to define our loss function\n",
    "              metrics=['accuracy'])\n",
    "#===\n",
    "tstart   = tf.timestamp()\n",
    "historyB = modelB.fit(X_train, Y_train, verbose=1,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split = 0.2) \n",
    "total_time = tf.timestamp() - tstart\n",
    "print(\"total time %3.3f seconds\"%total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#===    \n",
    "results_test = modelB.evaluate(X_test, Y_test, batch_size=128,verbose=0)    \n",
    "printAccuracy(historyB,results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the NN network, we had the best test accuracy of about 87.7% for the 2-layer network.  \n",
    "\n",
    "Here, we are quite a bit better at **88.8%**, and training on only **1/4**th the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training and test accuracy per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_result(historyB,results_test)   \n",
    "plt.title(\"Fashion MNIST 1-hidden layer CNN, in %3.2f s\"%(total_time))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and validation data could be lower here, because the values were recorded with **Dropout** on, however when the network is run on the **Test** data, **Dropout** is off.\n",
    "\n",
    "We are also overtraining a bit, and could probably turn up the dropout or decrease the number of neurons in the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelB.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict classes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### y_hat = modelB.predict_classes(X_test) ### this is deprecated\n",
    "y_hat = np.argmax(modelB.predict(X_test), axis=-1) #working version\n",
    "pd.crosstab(y_hat, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 convolutional layers\n",
    "\n",
    "Putting two layers of convolution immediately after one another tends to produce very predictive models. Here, we also follow the convolution layers by a dense hidden layer. Note that training this model takes **significantly** longer than the dense models to run. As such, I ran only the first 1000 samples. Using all of them should yield a classification rate near 99.5% on the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs      = 10\n",
    "batch_size  = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)                             # set our initial seed\n",
    "#=======\n",
    "modelC = tf.keras.models.Sequential([             # model type\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu',  \n",
    "                           padding='valid', input_shape=(28,28,1)),#, data_format='channels_first'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu',  \n",
    "                           padding='valid'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),                    # Dropout helps reduce overfitting \n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "#=======\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, nesterov=True, name='SGD')\n",
    "modelC.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',    #need to define our loss function\n",
    "              metrics=['accuracy'])\n",
    "#=======\n",
    "tstart   = tf.timestamp()\n",
    "historyC = modelC.fit(X_train, Y_train, verbose=1,\n",
    "                      epochs=epochs,\n",
    "                      batch_size=batch_size,\n",
    "                      validation_split = 0.2) \n",
    "                      \n",
    "total_time = tf.timestamp() - tstart\n",
    "print(\"total time %3.3f seconds\"%total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===    \n",
    "results_test = modelC.evaluate(X_test, Y_test, batch_size=128,verbose=0)    \n",
    "printAccuracy(historyC,results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training and test accuracy per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_result(historyC,results_test)   \n",
    "plt.title(\"Fashion MNIST 2-hidden layer CNN, in %3.2f s\"%(total_time))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelC.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Convolutions and Pooling\n",
    "\n",
    "This code will show us the convolutions graphically. The print (test_labels[;100]) shows us the first 100 labels in the test set, and you can see that the ones at index 0, index 23 and index 28 are all the same value (9). They're all shoes. Let's take a look at the result of running the convolution on each, and you'll begin to see common features between them emerge. Now, when the DNN is training on that data, it's working with a lot less, and it's perhaps finding a commonality between shoes based on this convolution/pooling combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = modelB.layers[0].get_weights()[0]\n",
    "nW = W1.shape[3]\n",
    "plt.figure(figsize=(10, 10), frameon=False)\n",
    "for i in range(nW):\n",
    "    plt.subplot(4, 8, i + 1)\n",
    "    im = W1[:,:,:,i].reshape((3,3))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(im, cmap='gray',interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
